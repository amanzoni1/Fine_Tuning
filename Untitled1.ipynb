{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNb015zaJtdtWQLpyhVRqET"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["!pip install -q bitsandbytes\n","!pip install -q triton\n","!pip install -q transformers\n","!pip install -q peft\n","!pip install -q unsloth\n","\n","import torch\n","import time\n","import torch.nn as nn\n","import numpy as np\n","\n","# Helper functions for testing\n","def set_seed(seed):\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    np.random.seed(seed)\n","\n","def _F(s):\n","    return f\"File '{s}'\"\n","\n","def _C():\n","    import traceback\n","    return traceback.extract_stack()[-3][0]\n","\n","def assert_same(a, b, file, dtype):\n","    if a.shape != b.shape:\n","        print(f\"Shape mismatch: {a.shape} vs {b.shape}\")\n","        assert(False)\n","    if dtype == torch.float16:\n","        assert(torch.allclose(a, b, rtol = 1e-3, atol = 3e-3))\n","    else:\n","        assert(torch.allclose(a, b, rtol = 1e-3, atol = 3e-3))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Oj3H6TGLqJck","executionInfo":{"status":"ok","timestamp":1744741091251,"user_tz":-240,"elapsed":117176,"user":{"displayName":"Andrea Manzoni","userId":"10270637157141721665"}},"outputId":"4cd65e61-0efd-4e44-8445-6c0c1ab44789"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.1/76.1 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m107.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m82.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m96.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.7/192.7 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.1/162.1 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.8/127.8 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.4/43.4 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m67.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.6/123.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m18.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\n","tensorflow-metadata 1.17.0 requires protobuf<6.0.0,>=4.25.2; python_version >= \"3.11\", but you have protobuf 3.20.3 which is incompatible.\n","ydf 0.11.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 3.20.3 which is incompatible.\n","grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0m"]}]},{"cell_type":"code","source":[],"metadata":{"id":"2DFqHWCeqJUQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2Oi2DOA-pWlX","executionInfo":{"status":"ok","timestamp":1744741160038,"user_tz":-240,"elapsed":32664,"user":{"displayName":"Andrea Manzoni","userId":"10270637157141721665"}},"outputId":"8cc5ca48-1abc-4d7d-a17e-b60bb0cf7110"},"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-2-199ff913b294>:3: UserWarning: WARNING: Unsloth should be imported before transformers to ensure all optimizations are applied. Your code may run slower or encounter memory issues without these optimizations.\n","\n","Please restructure your imports with 'import unsloth' at the top of your file.\n","  from unsloth.kernels.utils import fast_dequantize\n"]},{"output_type":"stream","name":"stdout","text":["🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","Unsloth: Failed to patch Gemma3ForConditionalGeneration.\n","🦥 Unsloth Zoo will now patch everything to make training faster!\n"]}],"source":["from bitsandbytes.nn import Linear4bit\n","from transformers.activations import ACT2FN\n","from unsloth.kernels.utils import fast_dequantize\n","from peft.utils.integrations import dequantize_module_weight as peft_dequantize\n","def unsloth_dequantize(weight):\n","    return fast_dequantize(weight.weight, weight.weight.quant_state)\n","\n","def bnb_Linear4bit(hd, m, dtype = torch.float16):\n","    return Linear4bit(\n","        hd, m, bias = None,\n","        compute_dtype       = dtype,\n","        compress_statistics = True,\n","        quant_type          = \"nf4\",\n","    )\n","\n","# [NEW] as at 18th Feb 2025\n","def assert_correct_bnb(weight, dtype):\n","    assert(weight.weight.dtype == torch.uint8)\n","    assert(weight.weight.quant_state.dtype == dtype)\n","    assert(weight.weight.quant_state.absmax.dtype == torch.uint8)\n","    assert(weight.weight.quant_state.code.dtype == torch.float32)\n","    assert(weight.weight.quant_state.offset.dtype == torch.float32)\n","    assert(weight.weight.quant_state.blocksize == 64)\n","    assert(weight.weight.quant_state.state2.absmax.dtype == torch.float32)\n","    assert(weight.weight.quant_state.state2.code.dtype == torch.float32)\n","    assert(weight.weight.quant_state.state2.blocksize == 256)\n","\n","class MLP(nn.Module):\n","    def __init__(self, hd = 4096, m = 14336, dtype = torch.float16):\n","        super().__init__()\n","        self.gate_proj = bnb_Linear4bit(hd, m, dtype = dtype).to(\"cuda\")\n","        self.up_proj   = bnb_Linear4bit(hd, m, dtype = dtype).to(\"cuda\")\n","        self.down_proj = bnb_Linear4bit(m, hd, dtype = dtype).to(\"cuda\")\n","        # [NEW] as at 18th Feb 2025\n","        self.gate_proj.weight.quant_state.dtype = dtype\n","        self.up_proj  .weight.quant_state.dtype = dtype\n","        self.down_proj.weight.quant_state.dtype = dtype\n","        self.act_fn = ACT2FN[\"silu\"]\n","    def forward(self, x):\n","        return self.down_proj(self.act_fn(self.gate_proj(x)) * self.up_proj(x))\n","\n","def mlp_forward(X, mlp, fx):\n","    up   = X @ fx(mlp.  up_proj).t()\n","    gate = X @ fx(mlp.gate_proj).t()\n","    h = mlp.act_fn(gate) * up\n","    down = h @ fx(mlp.down_proj).t()\n","    return down\n","\n","def mlp_dequantize(X, mlp, fx):\n","    a = fx(mlp.  up_proj).t(); torch.cuda.synchronize()\n","    b = fx(mlp.gate_proj).t(); torch.cuda.synchronize()\n","    c = fx(mlp.down_proj).t(); torch.cuda.synchronize()\n","    return a, b, c\n","\n","def test_dequantize(dequantize_fx):\n","    elapsed = 0\n","    options = [\n","        (2, 3333, 2048,  8192, 3407, torch.float16),\n","        (5,  777, 1024,  4096, 3409, torch.bfloat16),\n","        (3, 2048, 4096, 14336, 3408, torch.bfloat16),\n","    ]\n","    for (bsz, qlen, hd, m, seed, dt) in options:\n","        set_seed(seed)\n","        torch.set_default_dtype(torch.float32)\n","        mlp = MLP(hd = hd, m = m, dtype = dt)\n","        X = torch.randn((bsz, qlen, hd), device = \"cuda\", dtype = dt)\n","        torch.cuda.synchronize()\n","\n","        # Warmup\n","        for _ in range(2):\n","            assert_same( mlp_forward(X, mlp, dequantize_fx), mlp(X), _F(_C()), dt)\n","            # [NEW] as at 18th Feb 2025\n","            assert_correct_bnb(mlp.  up_proj, dt)\n","            assert_correct_bnb(mlp.gate_proj, dt)\n","            assert_correct_bnb(mlp.down_proj, dt)\n","            a, b, c = mlp_dequantize(X, mlp, dequantize_fx)\n","            A, B, C = mlp_dequantize(X, mlp, unsloth_dequantize)\n","            assert_same(a, A, _F(_C()), dt)\n","            assert_same(b, B, _F(_C()), dt)\n","            assert_same(c, C, _F(_C()), dt)\n","\n","        # Benchmarking\n","        torch.cuda.synchronize()\n","        start = time.time()\n","        for _ in range(1000): mlp_dequantize(X, mlp, dequantize_fx)\n","        elapsed += time.time() - start\n","    return elapsed"]},{"cell_type":"code","source":["from triton import jit\n","import torch\n","import triton\n","import triton.language as tl\n","\n","# Global buffers for memory reuse\n","WEIGHT_BUFFERS = {}\n","\n","@triton.jit\n","def _dequantize_nf4_kernel(\n","    # Input pointers\n","    weight_ptr,\n","    absmax_ptr,\n","    code_ptr,\n","    offset_ptr,\n","    state2_absmax_ptr,\n","    state2_code_ptr,\n","    output_ptr,\n","\n","    # Dimensions and parameters\n","    n_elements,\n","    blocksize,\n","    state2_blocksize,\n","\n","    # Block size for parallelism\n","    BLOCK_SIZE: tl.constexpr,\n","):\n","    \"\"\"Simple linear kernel for NF4 dequantization.\"\"\"\n","    # Get program ID\n","    pid = tl.program_id(0)\n","\n","    # Calculate start offset\n","    offset = pid * BLOCK_SIZE\n","\n","    # Create a simple 1D processing range\n","    offsets = offset + tl.arange(0, BLOCK_SIZE)\n","    mask = offsets < n_elements\n","\n","    # Load quantized weights\n","    weight_ptrs = weight_ptr + offsets\n","    weights = tl.load(weight_ptrs, mask=mask, other=0)\n","\n","    # Extract NF4 values (lower 4 bits of each byte)\n","    nf4_indices = weights & 0xF\n","\n","    # Calculate block indices\n","    block_indices = offsets // blocksize\n","    state2_block_indices = offsets // state2_blocksize\n","\n","    # Load quantization parameters\n","    absmax_ptrs = absmax_ptr + block_indices\n","    absmax_indices = tl.load(absmax_ptrs, mask=mask, other=0)\n","\n","    offset_ptrs = offset_ptr + block_indices\n","    offset_vals = tl.load(offset_ptrs, mask=mask, other=0)\n","\n","    state2_absmax_ptrs = state2_absmax_ptr + state2_block_indices\n","    state2_absmax = tl.load(state2_absmax_ptrs, mask=mask, other=0)\n","\n","    state2_code_ptrs = state2_code_ptr + state2_block_indices\n","    state2_code = tl.load(state2_code_ptrs, mask=mask, other=0)\n","\n","    # Load code values\n","    code_ptrs = code_ptr + nf4_indices\n","    code_vals = tl.load(code_ptrs, mask=None, other=0)\n","\n","    absmax_code_ptrs = code_ptr + absmax_indices\n","    absmax_code_vals = tl.load(absmax_code_ptrs, mask=None, other=0)\n","\n","    # Perform dequantization\n","    dequantized_absmax = absmax_code_vals * state2_absmax * state2_code\n","    dequantized = code_vals * dequantized_absmax + offset_vals\n","\n","    # Store result\n","    output_ptrs = output_ptr + offsets\n","    tl.store(output_ptrs, dequantized, mask=mask)\n","\n","def _your_dequantize_nf4(weight, quant_state, out=None, use_global_buffer=True):\n","    \"\"\"\n","    Dequantize NF4 weights using a simplified approach for compatibility.\n","    \"\"\"\n","    # Get device and shape\n","    device = weight.device\n","    shape = weight.shape\n","    n_elements = weight.numel()\n","\n","    # Extract quantization parameters\n","    absmax = quant_state.absmax\n","    dtype = quant_state.dtype\n","    blocksize = quant_state.blocksize\n","    offset = quant_state.offset\n","    state2 = quant_state.state2\n","    absmax2 = state2.absmax\n","    code2 = state2.code\n","    blocksize2 = state2.blocksize\n","\n","    # Reuse buffer if requested\n","    if use_global_buffer:\n","        global WEIGHT_BUFFERS\n","        device_idx = device.index if hasattr(device, 'index') else 0\n","\n","        if device_idx not in WEIGHT_BUFFERS or WEIGHT_BUFFERS[device_idx] is None:\n","            WEIGHT_BUFFERS[device_idx] = torch.empty(n_elements, dtype=dtype, device=device)\n","\n","        buffer = WEIGHT_BUFFERS[device_idx]\n","        if n_elements > buffer.numel():\n","            buffer.resize_(n_elements)\n","\n","        out = buffer[:n_elements].view(shape)\n","    else:\n","        if out is None:\n","            out = torch.empty(shape, dtype=dtype, device=device)\n","\n","    # Get data pointers\n","    weight_ptr = weight.data_ptr()\n","    absmax_ptr = absmax.data_ptr()\n","    code_ptr = quant_state.code.data_ptr()\n","    offset_ptr = offset.data_ptr()\n","    state2_absmax_ptr = absmax2.data_ptr()\n","    state2_code_ptr = code2.data_ptr()\n","    output_ptr = out.data_ptr()\n","\n","    # Use a simple 1D grid for better compatibility\n","    BLOCK_SIZE = 1024  # Good balance for T4\n","    grid = (triton.cdiv(n_elements, BLOCK_SIZE),)\n","\n","    # Launch kernel\n","    _dequantize_nf4_kernel[grid](\n","        weight_ptr,\n","        absmax_ptr,\n","        code_ptr,\n","        offset_ptr,\n","        state2_absmax_ptr,\n","        state2_code_ptr,\n","        output_ptr,\n","        n_elements,\n","        blocksize,\n","        blocksize2,\n","        BLOCK_SIZE,\n","    )\n","\n","    # Handle transposition\n","    is_transposed = (weight.shape[0] == 1)\n","    return out.t() if is_transposed else out\n","\n","def your_dequantize_nf4(weight):\n","    \"\"\"\n","    Entry point function for dequantizing weights.\n","    \"\"\"\n","    return _your_dequantize_nf4(weight.weight.data, weight.weight.quant_state, use_global_buffer=True)"],"metadata":{"id":"VAhKrprQpb43","executionInfo":{"status":"ok","timestamp":1744741627773,"user_tz":-240,"elapsed":30,"user":{"displayName":"Andrea Manzoni","userId":"10270637157141721665"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["### TEST IT BELOW:\n","test_dequantize(your_dequantize_nf4)\n","\n","### CALCULATE SPEEDUP (hopefully 1.15x faster or more)\n","# test_dequantize(unsloth_dequantize) / test_dequantize(your_dequantize_nf4)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":634},"id":"ZEYo6FPUpb2P","executionInfo":{"status":"error","timestamp":1744741629485,"user_tz":-240,"elapsed":674,"user":{"displayName":"Andrea Manzoni","userId":"10270637157141721665"}},"outputId":"283eef50-19bc-403c-9df1-d38021450ea2"},"execution_count":13,"outputs":[{"output_type":"error","ename":"CompilationError","evalue":"at 32:14:\n    pid = tl.program_id(0)\n\n    # Calculate start offset\n    offset = pid * BLOCK_SIZE\n\n    # Create a simple 1D processing range\n    offsets = offset + tl.arange(0, BLOCK_SIZE)\n    mask = offsets < n_elements\n\n    # Load quantized weights\n    weight_ptrs = weight_ptr + offsets\n    weights = tl.load(weight_ptrs, mask=mask, other=0)\n              ^","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/triton/language/core.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m                              \"(`_builder` argument must be provided outside of JIT functions.)\")\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/triton/language/core.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(pointer, mask, other, boundary_check, padding_option, cache_modifier, eviction_policy, volatile, _builder)\u001b[0m\n\u001b[1;32m   1634\u001b[0m     \u001b[0mvolatile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_constexpr_to_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvolatile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1635\u001b[0;31m     return semantic.load(pointer, mask, other, boundary_check, padding_option, cache_modifier, eviction_policy,\n\u001b[0m\u001b[1;32m   1636\u001b[0m                          volatile, _builder)\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/triton/language/semantic.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(ptr, mask, other, boundary_check, padding_option, cache_modifier, eviction_policy, is_volatile, builder)\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0;31m# Load by a tensor of pointers or a pointer of scalar: `block_type<pointer_type<>>` or `pointer_type<>`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1141\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_load_legacy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboundary_check\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meviction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_volatile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuilder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/triton/language/semantic.py\u001b[0m in \u001b[0;36m_load_legacy\u001b[0;34m(ptr, mask, other, boundary_check, padding, cache, eviction, is_volatile, builder)\u001b[0m\n\u001b[1;32m   1068\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscalar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1069\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unsupported ptr type {ptr.type.__repr__()} in `tl.load`\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1070\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Unsupported ptr type <[1024], int64> in `tl.load`","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mCompilationError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-13-d75915ec7763>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### TEST IT BELOW:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtest_dequantize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myour_dequantize_nf4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m### CALCULATE SPEEDUP (hopefully 1.15x faster or more)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# test_dequantize(unsloth_dequantize) / test_dequantize(your_dequantize_nf4)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-2-199ff913b294>\u001b[0m in \u001b[0;36mtest_dequantize\u001b[0;34m(dequantize_fx)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m# Warmup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0massert_same\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mmlp_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdequantize_fx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_F\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m             \u001b[0;31m# [NEW] as at 18th Feb 2025\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0massert_correct_bnb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mup_proj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-2-199ff913b294>\u001b[0m in \u001b[0;36mmlp_forward\u001b[0;34m(X, mlp, fx)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmlp_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mup\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mfx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m  \u001b[0mup_proj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0mgate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mfx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgate_proj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgate\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-12-a0cee29c7757>\u001b[0m in \u001b[0;36myour_dequantize_nf4\u001b[0;34m(weight)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mEntry\u001b[0m \u001b[0mpoint\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdequantizing\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \"\"\"\n\u001b[0;32m--> 150\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_your_dequantize_nf4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquant_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_global_buffer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-12-a0cee29c7757>\u001b[0m in \u001b[0;36m_your_dequantize_nf4\u001b[0;34m(weight, quant_state, out, use_global_buffer)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;31m# Launch kernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m     _dequantize_nf4_kernel[grid](\n\u001b[0m\u001b[1;32m    129\u001b[0m         \u001b[0mweight_ptr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0mabsmax_ptr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0mmemorizes\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m         \"\"\"\n\u001b[0;32m--> 330\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarmup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m         \u001b[0;31m# return cast(T, functools.partial(cast(Callable, self.run), grid=grid))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/triton/runtime/jit.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, grid, warmup, *args, **kwargs)\u001b[0m\n\u001b[1;32m    621\u001b[0m             \u001b[0;31m# compile the kernel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m             \u001b[0msrc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mASTSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msignature\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconstants\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfigs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m             kernel = self.compile(\n\u001b[0m\u001b[1;32m    624\u001b[0m                 \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/triton/compiler/compiler.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(src, target, options)\u001b[0m\n\u001b[1;32m    271\u001b[0m     \u001b[0mmodule_map\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_module_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m         \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_ir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcodegen_fns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         \u001b[0mfilter_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/triton/compiler/compiler.py\u001b[0m in \u001b[0;36mmake_ir\u001b[0;34m(self, options, codegen_fns, module_map, context)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmake_ir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcodegen_fns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule_map\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         return ast_to_ttir(self.fn, self, context=context, options=options, codegen_fns=codegen_fns,\n\u001b[0m\u001b[1;32m    101\u001b[0m                            module_map=module_map)\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mCompilationError\u001b[0m: at 32:14:\n    pid = tl.program_id(0)\n\n    # Calculate start offset\n    offset = pid * BLOCK_SIZE\n\n    # Create a simple 1D processing range\n    offsets = offset + tl.arange(0, BLOCK_SIZE)\n    mask = offsets < n_elements\n\n    # Load quantized weights\n    weight_ptrs = weight_ptr + offsets\n    weights = tl.load(weight_ptrs, mask=mask, other=0)\n              ^"]}]},{"cell_type":"code","source":[],"metadata":{"id":"65F9UJUcpbzs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"U95DieX5pbxO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"2efK1CA2pbu3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"B9Xesbi3pbsM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"H0edg5RBpbpn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"moAantzApbm7"},"execution_count":null,"outputs":[]}]}